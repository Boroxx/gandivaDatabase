\chapter{Experimente und Evaluierung}
\label{Evaluierung}
\section{Index-basierte Messungen}

Ein Ziel der Arbeit ist es Daten in einer Datenbank schnell,performant und Index-basiert abzufragen.
Um auf die Schnelligkeit der Datenbankanwendung einzugehen wurden verschiedene Messungen in Betracht gezogen.

In den folgenden Messungen wurde die Latenz zwischen Client und Server außer Acht gelassen, da diese sehr stark vom Netzwerk abhängig ist. Da die Anfragen hier über einen Webserver entgegen genommen werden und man mit Aussicht in Richtung RDMA, im gleichen Netzwerk arbeitet, sollte die Latenz vermutlich nicht all zu hoch ausfallen.
Um die Zeit zwischen eines Zugriffs auf die Datenbankanwendung bis zur Antwort zu messen, wurde eine \texttt{StopWatch} vor dem Aufruf der Methode \texttt{checkStatementToMethod(String Statement, Table table)} eingeschaltet.
Die Messungen wurden mithilfe von drei SQL-Dumps getätigt. Jeder SQL-Dump enthält eine unterschiedliche Anzahl an Dateneinträgen.

\subsection{Messumgebung}
Der folgende Abschnitt beschreibt die technischen Daten der Messumgebung:

\begin{itemize}
 \item CPU: Intel(R) Core(TM) i7-4790K CPU @ 4.00GHz
 \item Memory: 2x 8GiB DIMM DDR3 Synchron 1600 MHz
 \item Linux: 5.13.0-39-generic 44~20.04.1-Ubuntu
\end{itemize}



\subsection{Datenbank-Initialisierung}
\begin{table}[H]
\begin{center}
    \begin{tabular}{| l | l | l | l |}
    \hline
    Anzahl der Iteration & 100 & 1000 & 10000 \\ \hline
    1& 189,20 & 245,5  & 578,7 \\ \hline
    2& 204,8 & 259,1 & 603,3 \\ \hline
    3& 216,2& 261,8 & 581,4 \\ \hline
    4& 189,6 & 266,1 & 558,9 \\ \hline
    5& 199,4 & 264,1 & 569,9 \\ \hline
	Durchschnitt & 199,84 & 259,32 & 587,4\\ \hline
    \end{tabular}
\end{center}
\caption{Zeit einer Datenbank-Initialisierung mit einem Datensatz von 100, 1000 und 10000 Einträgen in Millisekunden}
\label{tabelle_avarage_time}
\end{table}

Die Ergebnisse aus \ref{tabelle_avarage_time} zeigen, dass sich Dauer der Initialisierung bei einer zehnfachen Anzahl von Daten, circa verdoppelt.

\subsection{Datenbank-Anfragen}

In den folgenden Messungen werden drei verschiedene Datenanfragen auf einem Datensatz angewendet, welcher aus zwei Spalten besteht. Eine dieser Spalten bildet eine Zahl ab, welche auf einen Wert, mithilfe der Datenbankanfrage, gefiltert wird.

\begin{table}[H]
\begin{center}
    \begin{tabular}{| l | l | l | l |}
    \hline
    Anzahl der Iteration & 100 & 1000 & 10000 \\ \hline
    1& 340,1 & 338,3  & 345,3 \\ \hline
    2& 33,6 & 35,21 & 40,00\\ \hline
    3& 40,12& 33,68 & 32,80 \\ \hline
    4& 42,40 & 36,00 & 42,51 \\ \hline
    5& 53,20 & 51,68 & 34,24 \\ \hline
	Durchschnitt mit erster Iteration & 101,88 & 98,97 & 98,97\\ \hline
	Durchschnitt ohne erste Iteration & 42,33 & 39,14 & 37,39\\ \hline
    \end{tabular}
\end{center}
\caption{Dauer der Datenabfrage \texttt{(SELECT `numberrange` FROM table WHERE `numberrange` = WERT;)} mit einem Datensatz von 100, 1000 und 10000 Einträgen in Millisekunden. (WERT wurde hier mit zufälligen Zahlen ersetzt)}
\label{equalTabelle}
\end{table}

In den Ergebnissen aus der Tabelle\ref{equalTabelle} sieht man, dass die erste Abfrage der Datenbank deutlich mehr Zeit benötigt,als die darauffolgenden. Dies kann damit zusammenhängen, dass Gandiva benötigte Ressource, während der ersten Anfrage, erstmalig lädt und diese dann für die nächsten Anfragen griffbereit hat.
Schaut man sich die Messungen genauer an, wird deutlich, dass obwohl die Datensätze größer werden, keine großen Änderung bei der Dauer der Anfrage im Durchschnitt existieren.\\
Weitere Operatoren wie \texttt{greaterThan} oder \texttt{lowerThan} werden hier nicht betrachtet, da diese auf der gleichen Implementierung basieren und circa die gleichen durchschnittlichen Messwerte abdecken.

\subsection{Fazit der Messungen}

Um die Performance der Datenbankanwendung gegen eine Datenbank wie zum Beispiel die H2-Datenbank, realistisch testen zu können, müsste die Datenbankanwendung der Arbeit die gleichen Features unterstützen. Ansonsten könnte kein fairer Vergleich stattfinden. Hier ist zu sagen, dass diese Datenbankanwendung auf einen spezifischen Fall zugeschnitten wurde. Es werden nur die Memory-Adressen mit ihren Offsets als Datenantwort zurückgeliefert und nicht die Daten selber. 
Dies bedeutet, dass die Messungen im Vergleich zu Messungen von Datenbanken aus der echten Welt, erst die Hälfte des Prozesses hinter sich haben. 

Damit solch eine Messungen valide sind, müsste man mithilfe von Remote-Direct-Memory-Access auf den Hauptspeicher im Netzwerk zugreifen und diese Zeit des Zugriffs, auf die Zeit der Anfrage, dazu addieren.

Ebenfalls könnte man einen großen Performance-Vorteil erkennen, wenn die Operation einer Summierung von Spalten in der Datenbankanwendung implementiert werden würde.\\
Diese Aussage deckt sich dadurch, dass Apache Arrow ein Spalten-Format zur Persistenz der Daten im Hauptspeicher benutzt.



